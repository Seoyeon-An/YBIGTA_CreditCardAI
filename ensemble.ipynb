{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(41) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "\n",
    "val_df = pd.read_csv('./data/val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "\n",
    "new_train_df = train_df[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]\n",
    "new_val_df = val_df[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18','Class']]\n",
    "new_test_df = test_df[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010540369615627855"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = val_df['Class'].sum()/len(val_df)\n",
    "ratio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label_IF(model_pred):\n",
    "    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/miniconda3/envs/jhoon/lib/python3.8/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.785503270732222]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.62      0.53      0.57        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.81      0.77      0.79     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_IF = IsolationForest(n_estimators=150, max_samples=len(new_train_df), contamination = ratio, max_features = 1, random_state=77)\n",
    "model_IF.fit(new_train_df)\n",
    "\n",
    "pred = model_IF.predict(new_val_df.drop('Class',axis = 1))\n",
    "y = new_val_df['Class']\n",
    "\n",
    "pred_IF = get_pred_label_IF(pred)\n",
    "val_score = f1_score(y, pred_IF, average='macro')\n",
    "\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(y, pred_IF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_IF.predict(new_test_df)\n",
    "pred_IF = get_pred_label_IF(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(pred_IF > 0, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LR = 1e-2\n",
    "BS = 16384 # 2의 제곱승꼴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
    "            y = torch.FloatTensor([self.labels[index]])\n",
    "            return x, y\n",
    "            #self.x = self.df[index]\n",
    "            #self.y = self.labels[index]\n",
    "            #return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = MyDataset(df=val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층 정규화\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-5):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.weight.data.fill_(1.0)\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon) # 계층정규화 완료\n",
    "        return self.weight * x + self.bias # wx+b\n",
    "        \n",
    "# 활성화 함수\n",
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "        \n",
    "class AutoEncoder1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder1, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.ln = LayerNorm(5000)\n",
    "        self.ln1 = LayerNorm(3500)\n",
    "        self.ln2 = LayerNorm(2000)\n",
    "        self.ln3 = LayerNorm(1000)\n",
    "        \n",
    "        self.upblock1 = nn.Sequential(nn.Linear(30, 1000), nn.BatchNorm1d(1000),GELU())\n",
    "        self.upblock2 = nn.Sequential(nn.Linear(1000,2000), nn.BatchNorm1d(2000),GELU())\n",
    "        self.upblock3 = nn.Sequential(nn.Linear(2000,3500), nn.BatchNorm1d(3500),GELU())\n",
    "        self.upblock4 = nn.Sequential(nn.Linear(3500,5000), nn.BatchNorm1d(5000),GELU())\n",
    "\n",
    "        self.downblock1 = nn.Sequential(nn.Linear(5000, 3500),nn.BatchNorm1d(3500),GELU())\n",
    "        self.downblock2 = nn.Sequential(nn.Linear(3500, 2000),nn.BatchNorm1d(2000),GELU())\n",
    "        self.downblock3 = nn.Sequential(nn.Linear(2000, 1000),nn.BatchNorm1d(1000),GELU())\n",
    "        self.downblock4 = nn.Sequential(nn.Linear(1000, 300),nn.BatchNorm1d(300),GELU())\n",
    "        \n",
    "        self.fclayer = nn.Sequential(nn.Linear(300,30))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        upblock1_out = self.upblock1(x) \n",
    "        upblock2_out = self.upblock2(upblock1_out)\n",
    "        upblock3_out = self.upblock3(upblock2_out)\n",
    "        upblock4_out = self.upblock4(upblock3_out)\n",
    "        \n",
    "        downblock1_out = self.downblock1(self.ln(upblock4_out)) \n",
    "        skipblock1 = downblock1_out + upblock3_out\n",
    "        downblock2_out = self.downblock2(self.ln1(skipblock1))\n",
    "        skipblock2 = downblock2_out + upblock2_out\n",
    "        downblock3_out = self.downblock3(self.ln2(skipblock2))\n",
    "        skipblock3 = downblock3_out + upblock1_out \n",
    "        downblock4_out = self.downblock4(self.ln3(skipblock3))\n",
    "        \n",
    "        x = self.fclayer(downblock4_out)\n",
    "         \n",
    "        return x # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # Loss Function\n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        avg = 1\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = self.criterion(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 0.95)\n",
    "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score <= score and avg > np.mean(train_loss):\n",
    "                best_score = score\n",
    "                avg = np.mean(train_loss)\n",
    "                torch.save(model.module.state_dict(), './checkpoint/best_model.pth', _use_new_zipfile_serialization=False)\n",
    "                print('---------------------------')\n",
    "                print(f'Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train loss : [0.5132853133337838] Val Score : [0.02092859841809397])\n",
      "---------------------------\n",
      "Train loss : [0.5132853133337838] Val Score : [0.02092859841809397])\n",
      "Epoch : [1] Train loss : [0.2488231701510293] Val Score : [0.2906414832196451])\n",
      "---------------------------\n",
      "Train loss : [0.2488231701510293] Val Score : [0.2906414832196451])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f2514153f70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/common/miniconda3/envs/jhoon/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train loss : [0.1722170923437391] Val Score : [0.48495470474700497])\n",
      "---------------------------\n",
      "Train loss : [0.1722170923437391] Val Score : [0.48495470474700497])\n",
      "Epoch : [3] Train loss : [0.13155716338327952] Val Score : [0.506937276930102])\n",
      "---------------------------\n",
      "Train loss : [0.13155716338327952] Val Score : [0.506937276930102])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "model_autoencoder = nn.DataParallel(AutoEncoder1())\n",
    "model_autoencoder.eval()\n",
    "optimizer = torch.optim.Adam(params = model_autoencoder.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "trainer = Trainer(model_autoencoder, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoEncoder1(\n",
       "    (ln): LayerNorm()\n",
       "    (ln1): LayerNorm()\n",
       "    (ln2): LayerNorm()\n",
       "    (ln3): LayerNorm()\n",
       "    (upblock1): Sequential(\n",
       "      (0): Linear(in_features=30, out_features=1000, bias=True)\n",
       "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (upblock2): Sequential(\n",
       "      (0): Linear(in_features=1000, out_features=2000, bias=True)\n",
       "      (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (upblock3): Sequential(\n",
       "      (0): Linear(in_features=2000, out_features=3500, bias=True)\n",
       "      (1): BatchNorm1d(3500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (upblock4): Sequential(\n",
       "      (0): Linear(in_features=3500, out_features=5000, bias=True)\n",
       "      (1): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (downblock1): Sequential(\n",
       "      (0): Linear(in_features=5000, out_features=3500, bias=True)\n",
       "      (1): BatchNorm1d(3500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (downblock2): Sequential(\n",
       "      (0): Linear(in_features=3500, out_features=2000, bias=True)\n",
       "      (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (downblock3): Sequential(\n",
       "      (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (downblock4): Sequential(\n",
       "      (0): Linear(in_features=1000, out_features=300, bias=True)\n",
       "      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (fclayer): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=30, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autoencoder = AutoEncoder1()\n",
    "model_autoencoder.load_state_dict(torch.load('./checkpoint/best_model.pth'))\n",
    "model_autoencoder = nn.DataParallel(model_autoencoder)\n",
    "model_autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_df, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_test(model, thr, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for x in iter(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            _x = model(x)\n",
    "            \n",
    "            diff = cos(x, _x).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_val(model, thr, val_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for x in iter(val_loader):\n",
    "            x = x[0].float().to(device)\n",
    "            _x = model(x)\n",
    "            \n",
    "            diff = cos(x, _x).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_autoencoder = prediction_test(model_autoencoder, 0.95, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_autoencoder = prediction_val(model_autoencoder, 0.95, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_autoencoder.count(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label_ell(model_pred):\n",
    "    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.9236496787663914]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.86      0.83      0.85        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.93      0.92      0.92     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ell = EllipticEnvelope(support_fraction = 0.994, contamination = 0.00112, random_state = 42)\n",
    "model_ell.fit(train_df)\n",
    "val_x = val_df.drop(columns=['Class']) # Input Data\n",
    "val_y = val_df['Class'] # Label\n",
    "\n",
    "val_pred = model_ell.predict(val_x) # model_ell prediction\n",
    "val_pred = get_pred_label_ell(val_pred)\n",
    "val_score = f1_score(val_y, val_pred, average='macro')\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(val_y, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ell = model_ell.predict(test_df)\n",
    "pred_ell = get_pred_label_ell(pred_ell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(pred_ell > 0, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import sklearn\n",
    "import sklearn.preprocessing as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv').drop(columns=['ID'])\n",
    "valid_df = pd.read_csv('./data/val.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "train_std = std_scaler.fit_transform(train_df)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "prcomponent = pca.fit_transform(train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal = pd.DataFrame(data=prcomponent, columns = ['pca_v1', 'pca_v2', 'pca_v3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]*\n",
      "optimization finished, #iter = 125\n",
      "obj = 5604.916372, rho = 102.273070\n",
      "nSV = 114, nBSV = 113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneClassSVM(gamma=0.0001, max_iter=100000, nu=0.001, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneClassSVM</label><div class=\"sk-toggleable__content\"><pre>OneClassSVM(gamma=0.0001, max_iter=100000, nu=0.001, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneClassSVM(gamma=0.0001, max_iter=100000, nu=0.001, verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = svm.OneClassSVM(gamma=0.0001, kernel='rbf', max_iter=100000, nu=0.001, verbose=True)\n",
    "model_svm.fit(principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_std = std_scaler.fit_transform(val_df)\n",
    "prcomponent_ = pca.fit_transform(valid_std)\n",
    "principal_ = pd.DataFrame(data=prcomponent_, columns = ['pca_v1', 'pca_v2', 'pca_v3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label(model, x, k):\n",
    "    prob = model.score_samples(x)\n",
    "    prob = torch.tensor(prob, dtype = torch.float)\n",
    "    topk_indices = torch.topk(prob, k = k, largest = False).indices\n",
    "\n",
    "    pred = torch.zeros(len(x), dtype = torch.long)\n",
    "    pred[topk_indices] = 1\n",
    "    return pred.tolist(), prob.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = val_df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.9137051774467988]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.86      0.80      0.83        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.93      0.90      0.91     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n",
      "tp :  24 , fp :  4 , tn :  28428 , fn :  6\n"
     ]
    }
   ],
   "source": [
    "val_pred, val_prob = get_pred_label(model_svm, principal_, 28)\n",
    "val_score = f1_score(lab, val_pred, average='macro')\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(lab, val_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(lab, val_pred).ravel()\n",
    "print('tp : ', tp, ', fp : ', fp, ', tn : ', tn, ', fn : ', fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label_SVM(model_pred):\n",
    "    model_pred = np.where(model_pred == 1, 0, model_pred)\n",
    "    model_pred = np.where(model_pred == -1, 1, model_pred)\n",
    "    return model_pred\n",
    "\n",
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "test_df = pd.read_csv('./data/test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_t = test_df.columns\n",
    "test_df_std = std_scaler.fit_transform(test_df)\n",
    "test_df_std_ = pd.DataFrame(data=test_df_std, columns=col_t)\n",
    "\n",
    "prcomponent_ = pca.fit_transform(test_df_std_)\n",
    "principal_ = pd.DataFrame(data=prcomponent_, columns = ['pca_v1', 'pca_v2', 'pca_v3'])\n",
    "\n",
    "test_pred = model_svm.predict(principal_)\n",
    "test_pred = get_pred_label_SVM(test_pred)\n",
    "\n",
    "submit['Class'] = test_pred\n",
    "submit.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def mode (x) :\n",
    "    cnt = Counter(x)\n",
    "    mode = cnt.most_common(1)\n",
    "    return mode[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_df, False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(modelset, x):\n",
    "    if modelset == None:\n",
    "        pred = None\n",
    "        \n",
    "    elif modelset[0] == 'Autoencoder':\n",
    "        # pred = prediction(modelset[1], 0.95, test_loader, device)\n",
    "        pred = prediction_val(modelset[1], 0.95, val_loader, device)\n",
    "\n",
    "    elif modelset[0] == 'EllipticEnvelope':\n",
    "        pred = modelset[1].predict(x)\n",
    "        pred = get_pred_label_ell(pred)\n",
    "\n",
    "    elif modelset[0] == 'IF':\n",
    "        new_x = x[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]\n",
    "        pred = modelset[1].predict(new_x)\n",
    "        pred = get_pred_label_IF(pred)\n",
    "    \n",
    "    elif modelset[0] == 'SVM':\n",
    "        col_t = x.columns\n",
    "        test_df_std = std_scaler.fit_transform(x)\n",
    "        test_df_std_ = pd.DataFrame(data=test_df_std, columns=col_t)\n",
    "\n",
    "        prcomponent_ = pca.fit_transform(test_df_std_)\n",
    "        principal_ = pd.DataFrame(data=prcomponent_, columns = ['pca_v1', 'pca_v2', 'pca_v3'])\n",
    "\n",
    "        pred = model_svm.predict(principal_)\n",
    "        pred = get_pred_label_SVM(pred)\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_pred(x, modelset1=None, modelset2=None, modelset3=None, modelset4=None) :\n",
    "    print('start')\n",
    "    # pred autoencoder\n",
    "    # pred_auto = prediction(model1, 0.95, test_loader, device)\n",
    "    pred_model1 = get_pred(modelset1, x)\n",
    "    print('Model1 done')\n",
    "    \n",
    "    # pred ell\n",
    "    # pred_ell = model2.predict(x)\n",
    "    # pred_ell = get_pred_label_ell(pred_ell)\n",
    "    pred_model2 = get_pred(modelset2, x)\n",
    "    print('Model2 done')\n",
    "\n",
    "    # pred IF\n",
    "    # new_x = x[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]\n",
    "    # pred = model3.predict(new_x)\n",
    "    # pred_IF = get_pred_label_IF(pred)\n",
    "    pred_model3 = get_pred(modelset3, x)\n",
    "    print('Model3 done')\n",
    "\n",
    "    pred_model4 = get_pred(modelset4, x)\n",
    "    print('Model4 done')\n",
    "\n",
    "    if modelset4 == None:\n",
    "        preds = pd.DataFrame(zip(pred_model1, pred_model2, pred_model3))\n",
    "        preds.columns = ['pred_model1', 'pred_model2', 'pred_model3']\n",
    "        # preds['pred_IF'] = 0\n",
    "    else:\n",
    "        preds = pd.DataFrame(zip(pred_model1, pred_model2, pred_model3, pred_model4))\n",
    "        preds.columns = ['pred_model1', 'pred_model2', 'pred_model3', 'pred_model4']\n",
    "        \n",
    "    return preds, preds.apply(mode,axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_pred2(x, model1=None, model2=None, model3=None,) :\n",
    "    print('start')\n",
    "    # pred autoencoder\n",
    "    # pred_auto = prediction(model1, 0.95, test_loader, device)\n",
    "    pred_auto = prediction_val(model1, 0.95, val_loader, device)\n",
    "    print('Model1 done')\n",
    "    \n",
    "    # pred ell\n",
    "    pred_ell = model2.predict(x)\n",
    "    pred_ell = get_pred_label_ell(pred_ell)\n",
    "    print('Model2 done')\n",
    "\n",
    "    # pred IF\n",
    "    # new_x = x[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]\n",
    "    # pred = model3.predict(new_x)\n",
    "    # pred_IF = get_pred_label_IF(pred)\n",
    "\n",
    "    # pred oneSVM\n",
    "    col_t = x.columns\n",
    "    test_df_std = std_scaler.fit_transform(x)\n",
    "    test_df_std_ = pd.DataFrame(data=test_df_std, columns=col_t)\n",
    "\n",
    "    prcomponent_ = pca.fit_transform(test_df_std_)\n",
    "    principal_ = pd.DataFrame(data=prcomponent_, columns = ['pca_v1', 'pca_v2', 'pca_v3'])\n",
    "\n",
    "    pred_svm = model3.predict(principal_)\n",
    "    pred_svm = get_pred_label_SVM(pred_svm)\n",
    "\n",
    "    print('Model3 done')\n",
    "\n",
    "    preds = pd.DataFrame(zip(pred_auto, pred_ell, pred_svm))\n",
    "    preds.columns = ['pred_model1', 'pred_model2', 'pred_model3']\n",
    "    # preds['pred_IF'] = 0\n",
    "        \n",
    "    return preds, preds.apply(mode,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Model1 done\n",
      "Model2 done\n",
      "Model3 done\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n",
      "!!!!\n"
     ]
    }
   ],
   "source": [
    "val_x = val_df.drop(columns=['Class'])\n",
    "val_y = val_df['Class']\n",
    "preds_df, preds  = get_ensemble_pred2(val_x, model1=model_autoencoder, model2=model_ell, model3=model_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28462.0\n",
       "mean         0.0\n",
       "std          0.0\n",
       "min          0.0\n",
       "25%          0.0\n",
       "50%          0.0\n",
       "75%          0.0\n",
       "max          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = preds_df[preds_df['pred_model2']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_model1</th>\n",
       "      <th>pred_model2</th>\n",
       "      <th>pred_model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pred_model1, pred_model2, pred_model3]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_1[preds_1['pred_model3']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelset_auto = ('Autoencoder', model_autoencoder)\n",
    "modelset_ell = ('EllipticEnvelope', model_ell)\n",
    "modelset_IF = ('IF', model_IF)\n",
    "modelset_onesvm = ('SVM', model_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelset_auto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m val_x \u001b[39m=\u001b[39m val_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m val_y \u001b[39m=\u001b[39m val_df[\u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m preds_df, preds  \u001b[39m=\u001b[39m get_ensemble_pred(val_x, modelset1\u001b[39m=\u001b[39mmodelset_auto, modelset2\u001b[39m=\u001b[39mmodelset_ell, modelset3\u001b[39m=\u001b[39mmodelset_onesvm)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelset_auto' is not defined"
     ]
    }
   ],
   "source": [
    "val_x = val_df.drop(columns=['Class'])\n",
    "val_y = val_df['Class']\n",
    "preds_df, preds  = get_ensemble_pred(val_x, modelset1=modelset_auto, modelset2=modelset_ell, modelset3=modelset_onesvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = preds_df[preds_df['pred_model3']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_model1</th>\n",
       "      <th>pred_model2</th>\n",
       "      <th>pred_model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9810</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16346</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16577</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16777</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17635</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17803</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21407</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21657</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22812</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_model1  pred_model2  pred_model3\n",
       "3508             0            0            1\n",
       "5384             0            0            1\n",
       "5393             0            0            1\n",
       "5637             0            0            1\n",
       "7211             0            0            1\n",
       "7890             0            0            1\n",
       "9810             0            0            1\n",
       "15531            0            0            1\n",
       "16346            0            0            1\n",
       "16521            0            0            1\n",
       "16577            0            0            1\n",
       "16777            0            0            1\n",
       "17635            0            0            1\n",
       "17803            0            0            1\n",
       "18121            0            0            1\n",
       "18921            0            0            1\n",
       "18945            0            0            1\n",
       "19002            0            0            1\n",
       "21407            0            0            1\n",
       "21657            0            0            1\n",
       "21895            0            0            1\n",
       "22398            0            0            1\n",
       "22812            0            0            1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_1[preds_1['pred_model3']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.4997363518121419]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.50      0.50      0.50     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/miniconda3/envs/jhoon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/common/miniconda3/envs/jhoon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/common/miniconda3/envs/jhoon/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "val_score = f1_score(val_y, preds, average='macro')\n",
    "\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(val_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_model1</th>\n",
       "      <th>pred_model2</th>\n",
       "      <th>pred_model3</th>\n",
       "      <th>pred_model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142503.000000</td>\n",
       "      <td>142503.000000</td>\n",
       "      <td>142503.000000</td>\n",
       "      <td>142503.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.046815</td>\n",
       "      <td>0.046591</td>\n",
       "      <td>0.042594</td>\n",
       "      <td>0.046740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_model1    pred_model2    pred_model3    pred_model4\n",
       "count  142503.000000  142503.000000  142503.000000  142503.000000\n",
       "mean        0.002196       0.002175       0.001818       0.002189\n",
       "std         0.046815       0.046591       0.042594       0.046740\n",
       "min         0.000000       0.000000       0.000000       0.000000\n",
       "25%         0.000000       0.000000       0.000000       0.000000\n",
       "50%         0.000000       0.000000       0.000000       0.000000\n",
       "75%         0.000000       0.000000       0.000000       0.000000\n",
       "max         1.000000       1.000000       1.000000       1.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['Class'] = preds\n",
    "submit.to_csv('./submit/ensemble_hardvoting_4_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3a9562b4cd7c3ad0d08ad9b8620f31dce258d0003dd8d12b9da203ced86495d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
