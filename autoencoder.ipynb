{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.device'>\n"
     ]
    }
   ],
   "source": [
    "print(type(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS: 전체 train dataset에 대하여 얼마나 training 할 것인가 <br>\n",
    "LR(learning rate): step size라고도 하며 gradient descent 할 때 얼마나 변경할 것인가 <br>\n",
    "BS(batch size): batch 1개에 dataset의 개수<br>\n",
    "SEED: random 값을 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000 \n",
    "LR = 1e-2\n",
    "BS = 10000\n",
    "SEED = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = pd.read_csv('./data/val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n",
    "\n",
    "val_dataset = MyDataset(df = val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chage hyperparameters in Neural Network\n",
    "1. LeakyReLU -> GELU </br>\n",
    "    최고 macro f1 score까지 더 빨리 왔지만 더이상 올라가지 않음 <br>\n",
    "    suppose: 아마 오답에 매우 가까운 정답이 있거나 정답에 매우 가까운 오답이 있음, 전자일 확률이 높음<br>\n",
    "    A: 정답에 매우 가까운 오답들이 너무 많음....(feat. EDA) \n",
    "    \n",
    "2. Linear layer를 더 늘려보자 =>  macro f1-score가 올라가다가 다시 내려감 결국 50으로...\n",
    "3. threshold를 더 늘려보자. 95% -> 98% => 85% 정도에서 고정..\n",
    "4. 원래 방식대로 차원을 줄이고 나서 늘려볼까? => 성능 더 안 좋음..\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(30,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,30),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vector_sim import TS_SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # Loss Function\n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self, ):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = self.criterion(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 10)\n",
    "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                torch.save(model.module.state_dict(), './checkpoint/best_model.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                # x: (batch size, 30)\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                \n",
    "                similarity = TS_SS(device=device)\n",
    "                diff = similarity(x, _x).cpu().tolist()\n",
    "                print(f\"Min: {min(diff)} / Max: {max(diff)}\")\n",
    "                batch_pred = np.where(np.array(diff)>thr, 1,0).tolist()\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 15.780115127563477 / Max: 106581.9296875\n",
      "Min: 13.719902038574219 / Max: 32662.65234375\n",
      "Min: 10.676398277282715 / Max: 29531.91015625\n",
      "Epoch : [0] Train loss : [0.46706242362658185] Val Score : [0.0010529271374420891])\n",
      "Min: 13.68333625793457 / Max: 47576.1640625\n",
      "Min: 12.625732421875 / Max: 53288.546875\n",
      "Min: 12.893082618713379 / Max: 33076.66015625\n",
      "Epoch : [1] Train loss : [0.2670592355231444] Val Score : [0.0010529271374420891])\n",
      "Min: 8.459122657775879 / Max: 29979.78515625\n",
      "Min: 8.144327163696289 / Max: 39202.8359375\n",
      "Min: 7.951747894287109 / Max: 18465.51953125\n",
      "Epoch : [2] Train loss : [0.19676533589760462] Val Score : [0.005120563395392736])\n",
      "Min: 3.687180519104004 / Max: 18664.390625\n",
      "Min: 3.610445737838745 / Max: 25044.474609375\n",
      "Min: 3.191511631011963 / Max: 7777.49609375\n",
      "Epoch : [3] Train loss : [0.1644363341232141] Val Score : [0.1929627928639546])\n",
      "Min: 2.308039903640747 / Max: 14302.421875\n",
      "Min: 2.2992610931396484 / Max: 18027.994140625\n",
      "Min: 1.9727038145065308 / Max: 5471.97216796875\n",
      "Epoch : [4] Train loss : [0.1462553491195043] Val Score : [0.32787965665068214])\n",
      "Min: 1.9137459993362427 / Max: 12768.61328125\n",
      "Min: 1.643803596496582 / Max: 15903.9169921875\n",
      "Min: 1.570033073425293 / Max: 5229.9228515625\n",
      "Epoch : [5] Train loss : [0.13371785605947176] Val Score : [0.39216390404625523])\n",
      "Min: 1.4144628047943115 / Max: 11224.88671875\n",
      "Min: 1.3202208280563354 / Max: 13245.0634765625\n",
      "Min: 1.0966124534606934 / Max: 3806.9814453125\n",
      "Epoch : [6] Train loss : [0.12471152345339458] Val Score : [0.42319755054958574])\n",
      "Min: 1.4184849262237549 / Max: 9674.0615234375\n",
      "Min: 1.2022573947906494 / Max: 10609.4580078125\n",
      "Min: 0.7637084126472473 / Max: 2849.072265625\n",
      "Epoch : [7] Train loss : [0.11965919348100822] Val Score : [0.45430602683026144])\n",
      "Min: 1.1941112279891968 / Max: 8396.5634765625\n",
      "Min: 0.9002560377120972 / Max: 8938.5849609375\n",
      "Min: 0.7113196849822998 / Max: 2379.361083984375\n",
      "Epoch : [8] Train loss : [0.1137764472514391] Val Score : [0.46631744198925973])\n",
      "Min: 1.036278486251831 / Max: 8530.4443359375\n",
      "Min: 1.0455604791641235 / Max: 8770.26953125\n",
      "Min: 0.7278079986572266 / Max: 2457.79541015625\n",
      "Epoch : [9] Train loss : [0.1114069689065218] Val Score : [0.4654461598623741])\n",
      "Min: 1.1486752033233643 / Max: 8539.69921875\n",
      "Min: 0.932912290096283 / Max: 8774.0576171875\n",
      "Min: 0.7148570418357849 / Max: 2525.002197265625\n",
      "Epoch : [10] Train loss : [0.10850465359787147] Val Score : [0.46681271938464974])\n",
      "Min: 0.971743643283844 / Max: 7988.43212890625\n",
      "Min: 0.8360528945922852 / Max: 7964.203125\n",
      "Min: 0.5123646259307861 / Max: 1982.8868408203125\n",
      "Epoch : [11] Train loss : [0.10293178570767243] Val Score : [0.47425043132548195])\n",
      "Min: 0.8774816393852234 / Max: 7944.31787109375\n",
      "Min: 0.7412950992584229 / Max: 7754.79931640625\n",
      "Min: 0.46902260184288025 / Max: 1959.191650390625\n",
      "Epoch : [12] Train loss : [0.09857654136916001] Val Score : [0.47851051267257344])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f619f261f70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/common/miniconda3/envs/jhoon/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.84932941198349 / Max: 7831.13623046875\n",
      "Min: 0.7066828012466431 / Max: 7507.498046875\n",
      "Min: 0.47122296690940857 / Max: 1832.081298828125\n",
      "Epoch : [13] Train loss : [0.09588159434497356] Val Score : [0.4821448936534185])\n",
      "Min: 0.8365642428398132 / Max: 7470.1689453125\n",
      "Min: 0.6924500465393066 / Max: 6768.69482421875\n",
      "Min: 0.41346192359924316 / Max: 1681.590576171875\n",
      "Epoch : [14] Train loss : [0.09386853128671646] Val Score : [0.4840388096053177])\n",
      "Min: 0.8010923862457275 / Max: 7335.392578125\n",
      "Min: 0.6426610350608826 / Max: 6470.04833984375\n",
      "Min: 0.4902832508087158 / Max: 1616.86181640625\n",
      "Epoch : [15] Train loss : [0.091129786024491] Val Score : [0.48548093400736514])\n",
      "Min: 0.8794159889221191 / Max: 7764.587890625\n",
      "Min: 0.6259289383888245 / Max: 6812.66015625\n",
      "Min: 0.5260598063468933 / Max: 1838.993896484375\n",
      "Epoch : [16] Train loss : [0.0910023699204127] Val Score : [0.48352893073288505])\n",
      "Min: 0.886025071144104 / Max: 7309.12548828125\n",
      "Min: 0.6557742953300476 / Max: 6348.638671875\n",
      "Min: 0.4655502438545227 / Max: 1511.4478759765625\n",
      "Epoch : [17] Train loss : [0.08818596353133519] Val Score : [0.4860169870025603])\n",
      "Min: 0.7171112298965454 / Max: 7438.2724609375\n",
      "Min: 0.4871729910373688 / Max: 6296.29833984375\n",
      "Min: 0.3711998164653778 / Max: 1458.0255126953125\n",
      "Epoch : [18] Train loss : [0.08617174873749416] Val Score : [0.48987924005184746])\n",
      "Min: 0.7475610375404358 / Max: 7416.20068359375\n",
      "Min: 0.5582001805305481 / Max: 6146.89111328125\n",
      "Min: 0.4499741196632385 / Max: 1444.3199462890625\n",
      "Epoch : [19] Train loss : [0.08228917916615804] Val Score : [0.4885933417244945])\n",
      "Min: 0.7246190905570984 / Max: 7116.4658203125\n",
      "Min: 0.5396571755409241 / Max: 5932.201171875\n",
      "Min: 0.3520337641239166 / Max: 1451.3648681640625\n",
      "Epoch : [20] Train loss : [0.08129939002295335] Val Score : [0.4900796296172845])\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder())\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoEncoder(\n",
       "    (Encoder): Sequential(\n",
       "      (0): Linear(in_features=30, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (Decoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Linear(in_features=64, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load('./checkpoint/best_model.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3a9562b4cd7c3ad0d08ad9b8620f31dce258d0003dd8d12b9da203ced86495d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
