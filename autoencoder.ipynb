{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "LR = 1e-2\n",
    "BS = 16384\n",
    "SEED = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = pd.read_csv('./data/val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = MyDataset(df = val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(30,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,30),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # Loss Function\n",
    "        self.criterion = nn.L1Loss().to(self.device)\n",
    "        \n",
    "    def fit(self, ):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = self.criterion(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 0.95)\n",
    "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                diff = cos(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train loss : [0.5370450871331351] Val Score : [0.002634815387243845])\n",
      "Epoch : [1] Train loss : [0.3531957907336099] Val Score : [0.11333899113982207])\n",
      "Epoch : [2] Train loss : [0.2670672152723585] Val Score : [0.3062632264948275])\n",
      "Epoch : [3] Train loss : [0.21747257454054697] Val Score : [0.37644644225698504])\n",
      "Epoch : [4] Train loss : [0.18641312846115657] Val Score : [0.4459559540831641])\n",
      "Epoch : [5] Train loss : [0.16548985881464823] Val Score : [0.4716268132617845])\n",
      "Epoch : [6] Train loss : [0.15047782020909445] Val Score : [0.4852044440925627])\n",
      "Epoch : [7] Train loss : [0.1402368630681719] Val Score : [0.4923244362930635])\n",
      "Epoch : [8] Train loss : [0.13190096190997533] Val Score : [0.4970552883739736])\n",
      "Epoch : [9] Train loss : [0.12730432727507182] Val Score : [0.500237456548652])\n",
      "Epoch : [10] Train loss : [0.12133762453283582] Val Score : [0.5020967958871082])\n",
      "Epoch : [11] Train loss : [0.11743042937346868] Val Score : [0.5039959969348181])\n",
      "Epoch : [12] Train loss : [0.11301388272217341] Val Score : [0.5047499335938982])\n",
      "Epoch : [13] Train loss : [0.10962770453521184] Val Score : [0.5077796597213174])\n",
      "Epoch : [14] Train loss : [0.10520371901137489] Val Score : [0.5093238771410732])\n",
      "Epoch : [15] Train loss : [0.103447182902268] Val Score : [0.5107812529684067])\n",
      "Epoch : [16] Train loss : [0.10034429069076266] Val Score : [0.512018539164737])\n",
      "Epoch : [17] Train loss : [0.09901266651494163] Val Score : [0.5130561342551924])\n",
      "Epoch : [18] Train loss : [0.0950013239468847] Val Score : [0.5156691576576046])\n",
      "Epoch : [19] Train loss : [0.09262267606598991] Val Score : [0.5163364849245786])\n",
      "Epoch : [20] Train loss : [0.09082837615694318] Val Score : [0.5173039098141923])\n",
      "Epoch : [21] Train loss : [0.08775521389075688] Val Score : [0.5187969919073012])\n",
      "Epoch : [22] Train loss : [0.08592358550855092] Val Score : [0.5193680391288173])\n",
      "Epoch : [23] Train loss : [0.08545586892536708] Val Score : [0.520271728755906])\n",
      "Epoch : [24] Train loss : [0.0841138841850417] Val Score : [0.5217176836612114])\n",
      "Epoch : [25] Train loss : [0.08307109986032758] Val Score : [0.5224535700316775])\n",
      "Epoch : [26] Train loss : [0.07925610989332199] Val Score : [0.5221043952670403])\n",
      "Epoch : [27] Train loss : [0.07827020649399076] Val Score : [0.524139450957535])\n",
      "Epoch : [28] Train loss : [0.07789413843836103] Val Score : [0.524761510660486])\n",
      "Epoch : [29] Train loss : [0.07782268524169922] Val Score : [0.5259544412021552])\n",
      "Epoch : [30] Train loss : [0.07912066578865051] Val Score : [0.5262106360917412])\n",
      "Epoch : [31] Train loss : [0.07752669602632523] Val Score : [0.526313884469248])\n",
      "Epoch : [32] Train loss : [0.07437602962766375] Val Score : [0.529223937149651])\n",
      "Epoch : [33] Train loss : [0.0733305396778243] Val Score : [0.5317381185273695])\n",
      "Epoch : [34] Train loss : [0.07268798777035304] Val Score : [0.5342447543786599])\n",
      "Epoch : [35] Train loss : [0.06950747860329491] Val Score : [0.5344591518178194])\n",
      "Epoch : [36] Train loss : [0.07170179805585317] Val Score : [0.5368627250477384])\n",
      "Epoch : [37] Train loss : [0.06934826927525657] Val Score : [0.5399419184147821])\n",
      "Epoch : [38] Train loss : [0.07005152744906289] Val Score : [0.5435077960045478])\n",
      "Epoch : [39] Train loss : [0.07148804728473936] Val Score : [0.545687326564355])\n",
      "Epoch : [40] Train loss : [0.06780013229165759] Val Score : [0.5499639140767333])\n",
      "Epoch : [41] Train loss : [0.06634422444871493] Val Score : [0.5564006733516096])\n",
      "Epoch : [42] Train loss : [0.06533676811626979] Val Score : [0.5577905582644318])\n",
      "Epoch : [43] Train loss : [0.06592491162674767] Val Score : [0.5595695120153324])\n",
      "Epoch : [44] Train loss : [0.06729703077248164] Val Score : [0.5579485464511985])\n",
      "Epoch : [45] Train loss : [0.06559304147958755] Val Score : [0.5625091554978082])\n",
      "Epoch : [46] Train loss : [0.06476618509207453] Val Score : [0.5630538733131271])\n",
      "Epoch : [47] Train loss : [0.06648316872971398] Val Score : [0.5716480581173843])\n",
      "Epoch : [48] Train loss : [0.06271811361823763] Val Score : [0.578890323326525])\n",
      "Epoch : [49] Train loss : [0.06301756895014218] Val Score : [0.584088028027516])\n",
      "Epoch : [50] Train loss : [0.0604071957724435] Val Score : [0.6007476543609798])\n",
      "Epoch : [51] Train loss : [0.05953293879117284] Val Score : [0.6164962591525004])\n",
      "Epoch : [52] Train loss : [0.06241179523723466] Val Score : [0.664673406571051])\n",
      "Epoch : [53] Train loss : [0.05857293467436518] Val Score : [0.7077171795413468])\n",
      "Epoch : [54] Train loss : [0.05766566736357553] Val Score : [0.7059866032567539])\n",
      "Epoch : [55] Train loss : [0.058930100074836185] Val Score : [0.6946258319247834])\n",
      "Epoch : [56] Train loss : [0.058905446103640964] Val Score : [0.7094766927103557])\n",
      "Epoch : [57] Train loss : [0.05778776801058224] Val Score : [0.7077171795413468])\n",
      "Epoch : [58] Train loss : [0.05649230097021375] Val Score : [0.7059866032567539])\n",
      "Epoch : [59] Train loss : [0.05572685439671789] Val Score : [0.7094766927103557])\n",
      "Epoch : [60] Train loss : [0.05814195583973612] Val Score : [0.7077171795413468])\n",
      "Epoch : [61] Train loss : [0.05631682649254799] Val Score : [0.7130854976190938])\n",
      "Epoch : [62] Train loss : [0.054583630923713954] Val Score : [0.7077171795413468])\n",
      "Epoch : [63] Train loss : [0.05550010395901544] Val Score : [0.7077171795413468])\n",
      "Epoch : [64] Train loss : [0.056272099592856] Val Score : [0.7168192118976862])\n",
      "Epoch : [65] Train loss : [0.05552626720496586] Val Score : [0.7168192118976862])\n",
      "Epoch : [66] Train loss : [0.0528739153274468] Val Score : [0.7246883762645999])\n",
      "Epoch : [67] Train loss : [0.05718920113784926] Val Score : [0.7267446884090669])\n",
      "Epoch : [68] Train loss : [0.0527285992034844] Val Score : [0.7376112450647377])\n",
      "Epoch : [69] Train loss : [0.052131070622376034] Val Score : [0.7187349645015549])\n",
      "Epoch : [70] Train loss : [0.052264162472316196] Val Score : [0.7288385690883094])\n",
      "Epoch : [71] Train loss : [0.052408289696489065] Val Score : [0.7246883762645999])\n",
      "Epoch : [72] Train loss : [0.05590384187442916] Val Score : [0.7206844679680786])\n",
      "Epoch : [73] Train loss : [0.05293860499347959] Val Score : [0.7353562550268086])\n",
      "Epoch : [74] Train loss : [0.05211075874311583] Val Score : [0.7331432493795871])\n",
      "Epoch : [75] Train loss : [0.05200117507151195] Val Score : [0.7353562550268086])\n",
      "Epoch : [76] Train loss : [0.053982753838811605] Val Score : [0.7376112450647377])\n",
      "Epoch : [77] Train loss : [0.04964670059936387] Val Score : [0.7399094305905288])\n",
      "Epoch : [78] Train loss : [0.0509256763117654] Val Score : [0.752094104263044])\n",
      "Epoch : [79] Train loss : [0.05065420429621424] Val Score : [0.7470759905302604])\n",
      "Epoch : [80] Train loss : [0.049918358347245624] Val Score : [0.7495600450513867])\n",
      "Epoch : [81] Train loss : [0.05193939911467688] Val Score : [0.7399094305905288])\n",
      "Epoch : [82] Train loss : [0.0507735013961792] Val Score : [0.752094104263044])\n",
      "Epoch : [83] Train loss : [0.048875348908560615] Val Score : [0.752094104263044])\n",
      "Epoch : [84] Train loss : [0.049136372549193244] Val Score : [0.752094104263044])\n",
      "Epoch : [85] Train loss : [0.04843134220157351] Val Score : [0.7573184229436457])\n",
      "Epoch : [86] Train loss : [0.05119315215519497] Val Score : [0.7422520697342344])\n",
      "Epoch : [87] Train loss : [0.05169644685728209] Val Score : [0.7600119366040216])\n",
      "Epoch : [88] Train loss : [0.048909809440374374] Val Score : [0.7600119366040216])\n",
      "Epoch : [89] Train loss : [0.046740801206656864] Val Score : [0.762761970120889])\n",
      "Epoch : [90] Train loss : [0.046443751880100796] Val Score : [0.75467969893057])\n",
      "Epoch : [91] Train loss : [0.04667310203824725] Val Score : [0.7573184229436457])\n",
      "Epoch : [92] Train loss : [0.04552748639668737] Val Score : [0.7713696202996474])\n",
      "Epoch : [93] Train loss : [0.04566207794206483] Val Score : [0.762761970120889])\n",
      "Epoch : [94] Train loss : [0.04571670772773879] Val Score : [0.762761970120889])\n",
      "Epoch : [95] Train loss : [0.04566521516868046] Val Score : [0.7573184229436457])\n",
      "Epoch : [96] Train loss : [0.04891613019364221] Val Score : [0.762761970120889])\n",
      "Epoch : [97] Train loss : [0.04735345606292997] Val Score : [0.7743645687973808])\n",
      "Epoch : [98] Train loss : [0.04863717034459114] Val Score : [0.7870308296420961])\n",
      "Epoch : [99] Train loss : [0.045892853289842606] Val Score : [0.7684388896488608])\n",
      "Epoch : [100] Train loss : [0.04516423706497465] Val Score : [0.7805557779616334])\n",
      "Epoch : [101] Train loss : [0.044504861746515544] Val Score : [0.7713696202996474])\n",
      "Epoch : [102] Train loss : [0.043144140392541885] Val Score : [0.7870308296420961])\n",
      "Epoch : [103] Train loss : [0.04370556665318353] Val Score : [0.7903809848799157])\n",
      "Epoch : [104] Train loss : [0.0462798321885722] Val Score : [0.7973199624677456])\n",
      "Epoch : [105] Train loss : [0.04582098924687931] Val Score : [0.7973199624677456])\n",
      "Epoch : [106] Train loss : [0.04614605754613876] Val Score : [0.8045965667777433])\n",
      "Epoch : [107] Train loss : [0.04529309379202979] Val Score : [0.8244378451249526])\n",
      "Epoch : [108] Train loss : [0.04507544317415783] Val Score : [0.8202665410912253])\n",
      "Epoch : [109] Train loss : [0.04534886138779776] Val Score : [0.8244378451249526])\n",
      "Epoch : [110] Train loss : [0.04667160340717861] Val Score : [0.8287186884323108])\n",
      "Epoch : [111] Train loss : [0.043119191591228755] Val Score : [0.8376267560436427])\n",
      "Epoch : [112] Train loss : [0.042174770895923884] Val Score : [0.8422634702634115])\n",
      "Epoch : [113] Train loss : [0.045556922044072835] Val Score : [0.872984830495149])\n",
      "Epoch : [114] Train loss : [0.04767073265143803] Val Score : [0.872984830495149])\n",
      "Epoch : [115] Train loss : [0.04329069011977741] Val Score : [0.8786471773914175])\n",
      "Epoch : [116] Train loss : [0.04272899563823428] Val Score : [0.890501890608512])\n",
      "Epoch : [117] Train loss : [0.045730847865343094] Val Score : [0.8844834793761085])\n",
      "Epoch : [118] Train loss : [0.043548976736409326] Val Score : [0.8844834793761085])\n",
      "Epoch : [119] Train loss : [0.042907801057611196] Val Score : [0.9031202878275757])\n",
      "Epoch : [120] Train loss : [0.04441746164645467] Val Score : [0.9097393418694286])\n",
      "Epoch : [121] Train loss : [0.04303288885525295] Val Score : [0.9097393418694286])\n",
      "Epoch : [122] Train loss : [0.04090552031993866] Val Score : [0.9097393418694286])\n",
      "Epoch : [123] Train loss : [0.04224751144647598] Val Score : [0.9031202878275757])\n",
      "Epoch : [124] Train loss : [0.04448424652218819] Val Score : [0.9097393418694286])\n",
      "Epoch : [125] Train loss : [0.042439701833895276] Val Score : [0.9097393418694286])\n",
      "Epoch : [126] Train loss : [0.04162176645227841] Val Score : [0.9097393418694286])\n",
      "Epoch : [127] Train loss : [0.040174100548028946] Val Score : [0.9031202878275757])\n",
      "Epoch : [128] Train loss : [0.04491614816444261] Val Score : [0.9097393418694286])\n",
      "Epoch : [129] Train loss : [0.04278375740562167] Val Score : [0.9097393418694286])\n",
      "Epoch : [130] Train loss : [0.03981898884688105] Val Score : [0.9097393418694286])\n",
      "Epoch : [131] Train loss : [0.03988331024135862] Val Score : [0.9097393418694286])\n",
      "Epoch 00132: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch : [132] Train loss : [0.036038994789123535] Val Score : [0.9097393418694286])\n",
      "Epoch : [133] Train loss : [0.03151493998510497] Val Score : [0.9097393418694286])\n",
      "Epoch : [134] Train loss : [0.031686062791517804] Val Score : [0.9097393418694286])\n",
      "Epoch : [135] Train loss : [0.030716065051300184] Val Score : [0.9097393418694286])\n",
      "Epoch : [136] Train loss : [0.03239874036184379] Val Score : [0.9097393418694286])\n",
      "Epoch : [137] Train loss : [0.03020836678998811] Val Score : [0.9097393418694286])\n",
      "Epoch : [138] Train loss : [0.031628050176160674] Val Score : [0.9097393418694286])\n",
      "Epoch : [139] Train loss : [0.032772524282336235] Val Score : [0.9097393418694286])\n",
      "Epoch : [140] Train loss : [0.032828056918723245] Val Score : [0.9097393418694286])\n",
      "Epoch : [141] Train loss : [0.032695082149335315] Val Score : [0.9097393418694286])\n",
      "Epoch : [142] Train loss : [0.03674814317907606] Val Score : [0.9097393418694286])\n",
      "Epoch 00143: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch : [143] Train loss : [0.03303910233080387] Val Score : [0.9097393418694286])\n",
      "Epoch : [144] Train loss : [0.030777629198772565] Val Score : [0.9097393418694286])\n",
      "Epoch : [145] Train loss : [0.026503558403679302] Val Score : [0.9097393418694286])\n",
      "Epoch : [146] Train loss : [0.0280886460095644] Val Score : [0.9097393418694286])\n",
      "Epoch : [147] Train loss : [0.029822349282247678] Val Score : [0.9097393418694286])\n",
      "Epoch : [148] Train loss : [0.027512299695185254] Val Score : [0.9097393418694286])\n",
      "Epoch : [149] Train loss : [0.028818853997758458] Val Score : [0.9097393418694286])\n",
      "Epoch : [150] Train loss : [0.02877753121512277] Val Score : [0.9097393418694286])\n",
      "Epoch : [151] Train loss : [0.028383888570325717] Val Score : [0.9097393418694286])\n",
      "Epoch : [152] Train loss : [0.028827881972704614] Val Score : [0.9097393418694286])\n",
      "Epoch : [153] Train loss : [0.02957900134580476] Val Score : [0.9097393418694286])\n",
      "Epoch 00154: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch : [154] Train loss : [0.025130842679313252] Val Score : [0.9097393418694286])\n",
      "Epoch : [155] Train loss : [0.023886564320751598] Val Score : [0.9097393418694286])\n",
      "Epoch : [156] Train loss : [0.02388962358236313] Val Score : [0.9097393418694286])\n",
      "Epoch : [157] Train loss : [0.025301572999783924] Val Score : [0.9097393418694286])\n",
      "Epoch : [158] Train loss : [0.025820856115647724] Val Score : [0.9097393418694286])\n",
      "Epoch : [159] Train loss : [0.024891557970217297] Val Score : [0.9097393418694286])\n",
      "Epoch : [160] Train loss : [0.02522472771150725] Val Score : [0.9097393418694286])\n",
      "Epoch : [161] Train loss : [0.025121467454092845] Val Score : [0.9097393418694286])\n",
      "Epoch : [162] Train loss : [0.02536193361239774] Val Score : [0.9097393418694286])\n",
      "Epoch : [163] Train loss : [0.024171148825969015] Val Score : [0.9097393418694286])\n",
      "Epoch : [164] Train loss : [0.02308607367532594] Val Score : [0.9097393418694286])\n",
      "Epoch 00165: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch : [165] Train loss : [0.026152800768613815] Val Score : [0.9097393418694286])\n",
      "Epoch : [166] Train loss : [0.024525016280157224] Val Score : [0.9097393418694286])\n",
      "Epoch : [167] Train loss : [0.02288460625069482] Val Score : [0.9097393418694286])\n",
      "Epoch : [168] Train loss : [0.02408643572458199] Val Score : [0.9097393418694286])\n",
      "Epoch : [169] Train loss : [0.02261162070291383] Val Score : [0.9097393418694286])\n",
      "Epoch : [170] Train loss : [0.024064046729888235] Val Score : [0.9097393418694286])\n",
      "Epoch : [171] Train loss : [0.020939269768340246] Val Score : [0.9097393418694286])\n",
      "Epoch : [172] Train loss : [0.02252677216061524] Val Score : [0.9097393418694286])\n",
      "Epoch : [173] Train loss : [0.022268948278256824] Val Score : [0.9097393418694286])\n",
      "Epoch : [174] Train loss : [0.025268777140549252] Val Score : [0.9097393418694286])\n",
      "Epoch : [175] Train loss : [0.022338134103587697] Val Score : [0.9097393418694286])\n",
      "Epoch 00176: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch : [176] Train loss : [0.02522079274058342] Val Score : [0.9097393418694286])\n",
      "Epoch : [177] Train loss : [0.021887357213667462] Val Score : [0.9097393418694286])\n",
      "Epoch : [178] Train loss : [0.020964394190481732] Val Score : [0.9097393418694286])\n",
      "Epoch : [179] Train loss : [0.022324127544249808] Val Score : [0.9097393418694286])\n",
      "Epoch : [180] Train loss : [0.02271306940487453] Val Score : [0.9097393418694286])\n",
      "Epoch : [181] Train loss : [0.02264696093542235] Val Score : [0.9097393418694286])\n",
      "Epoch : [182] Train loss : [0.023488812680755342] Val Score : [0.9097393418694286])\n",
      "Epoch : [183] Train loss : [0.021242391584174975] Val Score : [0.9097393418694286])\n",
      "Epoch : [184] Train loss : [0.02212701897536005] Val Score : [0.9097393418694286])\n",
      "Epoch : [185] Train loss : [0.022252469190529416] Val Score : [0.9097393418694286])\n",
      "Epoch : [186] Train loss : [0.02141495474747249] Val Score : [0.9097393418694286])\n",
      "Epoch 00187: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch : [187] Train loss : [0.02332042290696076] Val Score : [0.9097393418694286])\n",
      "Epoch : [188] Train loss : [0.020443744957447052] Val Score : [0.9097393418694286])\n",
      "Epoch : [189] Train loss : [0.02226452236729009] Val Score : [0.9097393418694286])\n",
      "Epoch : [190] Train loss : [0.02353333548775741] Val Score : [0.9097393418694286])\n",
      "Epoch : [191] Train loss : [0.024193818281803812] Val Score : [0.9097393418694286])\n",
      "Epoch : [192] Train loss : [0.023639183225376264] Val Score : [0.9097393418694286])\n",
      "Epoch : [193] Train loss : [0.021765234481011118] Val Score : [0.9097393418694286])\n",
      "Epoch : [194] Train loss : [0.02061159403196403] Val Score : [0.9097393418694286])\n",
      "Epoch : [195] Train loss : [0.02374203396695001] Val Score : [0.9097393418694286])\n",
      "Epoch : [196] Train loss : [0.021278259743537222] Val Score : [0.9097393418694286])\n",
      "Epoch : [197] Train loss : [0.021070950531533787] Val Score : [0.9097393418694286])\n",
      "Epoch 00198: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch : [198] Train loss : [0.022416499044213976] Val Score : [0.9097393418694286])\n",
      "Epoch : [199] Train loss : [0.021084019115992954] Val Score : [0.9097393418694286])\n",
      "Epoch : [200] Train loss : [0.021973174331443652] Val Score : [0.9097393418694286])\n",
      "Epoch : [201] Train loss : [0.021719180845788548] Val Score : [0.9097393418694286])\n",
      "Epoch : [202] Train loss : [0.02317832170852593] Val Score : [0.9097393418694286])\n",
      "Epoch : [203] Train loss : [0.024210250803402493] Val Score : [0.9097393418694286])\n",
      "Epoch : [204] Train loss : [0.020857692563108036] Val Score : [0.9097393418694286])\n",
      "Epoch : [205] Train loss : [0.021612370386719704] Val Score : [0.9097393418694286])\n",
      "Epoch : [206] Train loss : [0.021105797429169928] Val Score : [0.9097393418694286])\n",
      "Epoch : [207] Train loss : [0.022691382095217705] Val Score : [0.9097393418694286])\n",
      "Epoch : [208] Train loss : [0.022089045494794846] Val Score : [0.9097393418694286])\n",
      "Epoch 00209: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch : [209] Train loss : [0.021840444366846765] Val Score : [0.9097393418694286])\n",
      "Epoch : [210] Train loss : [0.021441377433282987] Val Score : [0.9097393418694286])\n",
      "Epoch : [211] Train loss : [0.022097116336226463] Val Score : [0.9097393418694286])\n",
      "Epoch : [212] Train loss : [0.022229385961379324] Val Score : [0.9097393418694286])\n",
      "Epoch : [213] Train loss : [0.02294819456126009] Val Score : [0.9097393418694286])\n",
      "Epoch : [214] Train loss : [0.02110347550894533] Val Score : [0.9097393418694286])\n",
      "Epoch : [215] Train loss : [0.0222658815660647] Val Score : [0.9097393418694286])\n",
      "Epoch : [216] Train loss : [0.020971296621220454] Val Score : [0.9097393418694286])\n",
      "Epoch : [217] Train loss : [0.021348509405340468] Val Score : [0.9097393418694286])\n",
      "Epoch : [218] Train loss : [0.02245949980403696] Val Score : [0.9097393418694286])\n",
      "Epoch : [219] Train loss : [0.021185707300901413] Val Score : [0.9097393418694286])\n",
      "Epoch 00220: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch : [220] Train loss : [0.020845991426280568] Val Score : [0.9097393418694286])\n",
      "Epoch : [221] Train loss : [0.022844224103859494] Val Score : [0.9097393418694286])\n",
      "Epoch : [222] Train loss : [0.02387080847152642] Val Score : [0.9097393418694286])\n",
      "Epoch : [223] Train loss : [0.020496763288974762] Val Score : [0.9097393418694286])\n",
      "Epoch : [224] Train loss : [0.021076417128954614] Val Score : [0.9097393418694286])\n",
      "Epoch : [225] Train loss : [0.020525503105350902] Val Score : [0.9097393418694286])\n",
      "Epoch : [226] Train loss : [0.021464661562017033] Val Score : [0.9097393418694286])\n",
      "Epoch : [227] Train loss : [0.021128066150205477] Val Score : [0.9097393418694286])\n",
      "Epoch : [228] Train loss : [0.021875676832028797] Val Score : [0.9097393418694286])\n",
      "Epoch : [229] Train loss : [0.021140377702457563] Val Score : [0.9097393418694286])\n",
      "Epoch : [230] Train loss : [0.021735832627330507] Val Score : [0.9097393418694286])\n",
      "Epoch 00231: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch : [231] Train loss : [0.02032157060291086] Val Score : [0.9097393418694286])\n",
      "Epoch : [232] Train loss : [0.020550090287412916] Val Score : [0.9097393418694286])\n",
      "Epoch : [233] Train loss : [0.021352263167500496] Val Score : [0.9097393418694286])\n",
      "Epoch : [234] Train loss : [0.020882641630513326] Val Score : [0.9097393418694286])\n",
      "Epoch : [235] Train loss : [0.021116129521812712] Val Score : [0.9097393418694286])\n",
      "Epoch : [236] Train loss : [0.02013314382306167] Val Score : [0.9097393418694286])\n",
      "Epoch : [237] Train loss : [0.020773594666804587] Val Score : [0.9097393418694286])\n",
      "Epoch : [238] Train loss : [0.020036598401410238] Val Score : [0.9097393418694286])\n",
      "Epoch : [239] Train loss : [0.022286283650568554] Val Score : [0.9097393418694286])\n",
      "Epoch : [240] Train loss : [0.02304369450679847] Val Score : [0.9097393418694286])\n",
      "Epoch : [241] Train loss : [0.020666622423699925] Val Score : [0.9097393418694286])\n",
      "Epoch 00242: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch : [242] Train loss : [0.021726802257554873] Val Score : [0.9097393418694286])\n",
      "Epoch : [243] Train loss : [0.020568199721830233] Val Score : [0.9097393418694286])\n",
      "Epoch : [244] Train loss : [0.02205813835774149] Val Score : [0.9097393418694286])\n",
      "Epoch : [245] Train loss : [0.02352416142821312] Val Score : [0.9097393418694286])\n",
      "Epoch : [246] Train loss : [0.021909205242991447] Val Score : [0.9097393418694286])\n",
      "Epoch : [247] Train loss : [0.022960541769862175] Val Score : [0.9097393418694286])\n",
      "Epoch : [248] Train loss : [0.021656684843557223] Val Score : [0.9097393418694286])\n",
      "Epoch : [249] Train loss : [0.021347088739275932] Val Score : [0.9097393418694286])\n",
      "Epoch : [250] Train loss : [0.020339570407356535] Val Score : [0.9097393418694286])\n",
      "Epoch : [251] Train loss : [0.022769530436822345] Val Score : [0.9097393418694286])\n",
      "Epoch : [252] Train loss : [0.020977501092212542] Val Score : [0.9097393418694286])\n",
      "Epoch 00253: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch : [253] Train loss : [0.02205233009798186] Val Score : [0.9097393418694286])\n",
      "Epoch : [254] Train loss : [0.02033920506281512] Val Score : [0.9097393418694286])\n",
      "Epoch : [255] Train loss : [0.021739082677023753] Val Score : [0.9097393418694286])\n",
      "Epoch : [256] Train loss : [0.020687502143638476] Val Score : [0.9097393418694286])\n",
      "Epoch : [257] Train loss : [0.022123213857412338] Val Score : [0.9097393418694286])\n",
      "Epoch : [258] Train loss : [0.021581211260386875] Val Score : [0.9097393418694286])\n",
      "Epoch : [259] Train loss : [0.022278891344155585] Val Score : [0.9097393418694286])\n",
      "Epoch : [260] Train loss : [0.020154821553400586] Val Score : [0.9097393418694286])\n",
      "Epoch : [261] Train loss : [0.023952667202268327] Val Score : [0.9097393418694286])\n",
      "Epoch : [262] Train loss : [0.022237769727196013] Val Score : [0.9097393418694286])\n",
      "Epoch : [263] Train loss : [0.020864327970360006] Val Score : [0.9097393418694286])\n",
      "Epoch 00264: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch : [264] Train loss : [0.022557804360985756] Val Score : [0.9097393418694286])\n",
      "Epoch : [265] Train loss : [0.023159260196345195] Val Score : [0.9097393418694286])\n",
      "Epoch : [266] Train loss : [0.02172412377383028] Val Score : [0.9097393418694286])\n",
      "Epoch : [267] Train loss : [0.018767555111220906] Val Score : [0.9097393418694286])\n",
      "Epoch : [268] Train loss : [0.021128565073013306] Val Score : [0.9097393418694286])\n",
      "Epoch : [269] Train loss : [0.022847346695406095] Val Score : [0.9097393418694286])\n",
      "Epoch : [270] Train loss : [0.02075925629053797] Val Score : [0.9097393418694286])\n",
      "Epoch : [271] Train loss : [0.02294009631233556] Val Score : [0.9097393418694286])\n",
      "Epoch : [272] Train loss : [0.019659186048167094] Val Score : [0.9097393418694286])\n",
      "Epoch : [273] Train loss : [0.02217098724629198] Val Score : [0.9097393418694286])\n",
      "Epoch : [274] Train loss : [0.023754915754709924] Val Score : [0.9097393418694286])\n",
      "Epoch 00275: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch : [275] Train loss : [0.02309696323105267] Val Score : [0.9097393418694286])\n",
      "Epoch : [276] Train loss : [0.02162411729139941] Val Score : [0.9097393418694286])\n",
      "Epoch : [277] Train loss : [0.022505895101598332] Val Score : [0.9097393418694286])\n",
      "Epoch : [278] Train loss : [0.0213304412152086] Val Score : [0.9097393418694286])\n",
      "Epoch : [279] Train loss : [0.021000574742044722] Val Score : [0.9097393418694286])\n",
      "Epoch : [280] Train loss : [0.020026187811579024] Val Score : [0.9097393418694286])\n",
      "Epoch : [281] Train loss : [0.022848563800965036] Val Score : [0.9097393418694286])\n",
      "Epoch : [282] Train loss : [0.02166254605565752] Val Score : [0.9097393418694286])\n",
      "Epoch : [283] Train loss : [0.02202325314283371] Val Score : [0.9097393418694286])\n",
      "Epoch : [284] Train loss : [0.022124473537717546] Val Score : [0.9097393418694286])\n",
      "Epoch : [285] Train loss : [0.021789005558405603] Val Score : [0.9097393418694286])\n",
      "Epoch 00286: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch : [286] Train loss : [0.021726792146052634] Val Score : [0.9097393418694286])\n",
      "Epoch : [287] Train loss : [0.023869995826057026] Val Score : [0.9097393418694286])\n",
      "Epoch : [288] Train loss : [0.022041869748915945] Val Score : [0.9097393418694286])\n",
      "Epoch : [289] Train loss : [0.020933343363659724] Val Score : [0.9097393418694286])\n",
      "Epoch : [290] Train loss : [0.02016807853111199] Val Score : [0.9097393418694286])\n",
      "Epoch : [291] Train loss : [0.020793570737753595] Val Score : [0.9097393418694286])\n",
      "Epoch : [292] Train loss : [0.023002234952790395] Val Score : [0.9097393418694286])\n",
      "Epoch : [293] Train loss : [0.02292796703321593] Val Score : [0.9097393418694286])\n",
      "Epoch : [294] Train loss : [0.021950274173702513] Val Score : [0.9097393418694286])\n",
      "Epoch : [295] Train loss : [0.020727322037730898] Val Score : [0.9097393418694286])\n",
      "Epoch : [296] Train loss : [0.019922351464629173] Val Score : [0.9097393418694286])\n",
      "Epoch 00297: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch : [297] Train loss : [0.019337240074362074] Val Score : [0.9097393418694286])\n",
      "Epoch : [298] Train loss : [0.021762047495160784] Val Score : [0.9097393418694286])\n",
      "Epoch : [299] Train loss : [0.02103655811931406] Val Score : [0.9097393418694286])\n",
      "Epoch : [300] Train loss : [0.02275215568287032] Val Score : [0.9097393418694286])\n",
      "Epoch : [301] Train loss : [0.022047043112771853] Val Score : [0.9097393418694286])\n",
      "Epoch : [302] Train loss : [0.02151240807558809] Val Score : [0.9097393418694286])\n",
      "Epoch : [303] Train loss : [0.021661624578492984] Val Score : [0.9097393418694286])\n",
      "Epoch : [304] Train loss : [0.022133771064026014] Val Score : [0.9097393418694286])\n",
      "Epoch : [305] Train loss : [0.022067425240363394] Val Score : [0.9097393418694286])\n",
      "Epoch : [306] Train loss : [0.02089527009853295] Val Score : [0.9097393418694286])\n",
      "Epoch : [307] Train loss : [0.021306104958057404] Val Score : [0.9097393418694286])\n",
      "Epoch 00308: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch : [308] Train loss : [0.022994158789515495] Val Score : [0.9097393418694286])\n",
      "Epoch : [309] Train loss : [0.021881977362292155] Val Score : [0.9097393418694286])\n",
      "Epoch : [310] Train loss : [0.02120943633573396] Val Score : [0.9097393418694286])\n",
      "Epoch : [311] Train loss : [0.02105769781129701] Val Score : [0.9097393418694286])\n",
      "Epoch : [312] Train loss : [0.021013636674199785] Val Score : [0.9097393418694286])\n",
      "Epoch : [313] Train loss : [0.022905641368457248] Val Score : [0.9097393418694286])\n",
      "Epoch : [314] Train loss : [0.022944612428545952] Val Score : [0.9097393418694286])\n",
      "Epoch : [315] Train loss : [0.02027572425348418] Val Score : [0.9097393418694286])\n",
      "Epoch : [316] Train loss : [0.020931339423571314] Val Score : [0.9097393418694286])\n",
      "Epoch : [317] Train loss : [0.0211925386850323] Val Score : [0.9097393418694286])\n",
      "Epoch : [318] Train loss : [0.021153159173471586] Val Score : [0.9097393418694286])\n",
      "Epoch 00319: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch : [319] Train loss : [0.020030840166977475] Val Score : [0.9097393418694286])\n",
      "Epoch : [320] Train loss : [0.0209137855895928] Val Score : [0.9097393418694286])\n",
      "Epoch : [321] Train loss : [0.020781966724566052] Val Score : [0.9097393418694286])\n",
      "Epoch : [322] Train loss : [0.021632648472275053] Val Score : [0.9097393418694286])\n",
      "Epoch : [323] Train loss : [0.020633472129702568] Val Score : [0.9097393418694286])\n",
      "Epoch : [324] Train loss : [0.020730131172708104] Val Score : [0.9097393418694286])\n",
      "Epoch : [325] Train loss : [0.021539198234677315] Val Score : [0.9097393418694286])\n",
      "Epoch : [326] Train loss : [0.02059343909578664] Val Score : [0.9097393418694286])\n",
      "Epoch : [327] Train loss : [0.022398710516946658] Val Score : [0.9097393418694286])\n",
      "Epoch : [328] Train loss : [0.019937518185802867] Val Score : [0.9097393418694286])\n",
      "Epoch : [329] Train loss : [0.02154101830508028] Val Score : [0.9097393418694286])\n",
      "Epoch 00330: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch : [330] Train loss : [0.020642238003867015] Val Score : [0.9097393418694286])\n",
      "Epoch : [331] Train loss : [0.02048997873706477] Val Score : [0.9097393418694286])\n",
      "Epoch : [332] Train loss : [0.02157568426004478] Val Score : [0.9097393418694286])\n",
      "Epoch : [333] Train loss : [0.020995252100484713] Val Score : [0.9097393418694286])\n",
      "Epoch : [334] Train loss : [0.023440115685973848] Val Score : [0.9097393418694286])\n",
      "Epoch : [335] Train loss : [0.022426583671144078] Val Score : [0.9097393418694286])\n",
      "Epoch : [336] Train loss : [0.021239042016012327] Val Score : [0.9097393418694286])\n",
      "Epoch : [337] Train loss : [0.023997495749167035] Val Score : [0.9097393418694286])\n",
      "Epoch : [338] Train loss : [0.020714675741536275] Val Score : [0.9097393418694286])\n",
      "Epoch : [339] Train loss : [0.020790439365165576] Val Score : [0.9097393418694286])\n",
      "Epoch : [340] Train loss : [0.022051472749028887] Val Score : [0.9097393418694286])\n",
      "Epoch : [341] Train loss : [0.020696831601006643] Val Score : [0.9097393418694286])\n",
      "Epoch : [342] Train loss : [0.023090812510677745] Val Score : [0.9097393418694286])\n",
      "Epoch : [343] Train loss : [0.022228117500032698] Val Score : [0.9097393418694286])\n",
      "Epoch : [344] Train loss : [0.020710219496062825] Val Score : [0.9097393418694286])\n",
      "Epoch : [345] Train loss : [0.021123467811516354] Val Score : [0.9097393418694286])\n",
      "Epoch : [346] Train loss : [0.021934651902743747] Val Score : [0.9097393418694286])\n",
      "Epoch : [347] Train loss : [0.021212881430983543] Val Score : [0.9097393418694286])\n",
      "Epoch : [348] Train loss : [0.024620084624205316] Val Score : [0.9097393418694286])\n",
      "Epoch : [349] Train loss : [0.021201625200254575] Val Score : [0.9097393418694286])\n",
      "Epoch : [350] Train loss : [0.020430082455277443] Val Score : [0.9097393418694286])\n",
      "Epoch : [351] Train loss : [0.022819462897522107] Val Score : [0.9097393418694286])\n",
      "Epoch : [352] Train loss : [0.022304545023611615] Val Score : [0.9097393418694286])\n",
      "Epoch : [353] Train loss : [0.023531425212110792] Val Score : [0.9097393418694286])\n",
      "Epoch : [354] Train loss : [0.022351474102054323] Val Score : [0.9097393418694286])\n",
      "Epoch : [355] Train loss : [0.02105528488755226] Val Score : [0.9097393418694286])\n",
      "Epoch : [356] Train loss : [0.020062394174081937] Val Score : [0.9097393418694286])\n",
      "Epoch : [357] Train loss : [0.02323799394071102] Val Score : [0.9097393418694286])\n",
      "Epoch : [358] Train loss : [0.022113954116191183] Val Score : [0.9097393418694286])\n",
      "Epoch : [359] Train loss : [0.02085449386920248] Val Score : [0.9097393418694286])\n",
      "Epoch : [360] Train loss : [0.02231995921049799] Val Score : [0.9097393418694286])\n",
      "Epoch : [361] Train loss : [0.0208092350512743] Val Score : [0.9097393418694286])\n",
      "Epoch : [362] Train loss : [0.0222250475947346] Val Score : [0.9097393418694286])\n",
      "Epoch : [363] Train loss : [0.021266366754259382] Val Score : [0.9097393418694286])\n",
      "Epoch : [364] Train loss : [0.022267922492963926] Val Score : [0.9097393418694286])\n",
      "Epoch : [365] Train loss : [0.021411592672978128] Val Score : [0.9097393418694286])\n",
      "Epoch : [366] Train loss : [0.02047925442457199] Val Score : [0.9097393418694286])\n",
      "Epoch : [367] Train loss : [0.020904583324279104] Val Score : [0.9097393418694286])\n",
      "Epoch : [368] Train loss : [0.022772505081125667] Val Score : [0.9097393418694286])\n",
      "Epoch : [369] Train loss : [0.02297322585114411] Val Score : [0.9097393418694286])\n",
      "Epoch : [370] Train loss : [0.020940820021288737] Val Score : [0.9097393418694286])\n",
      "Epoch : [371] Train loss : [0.02267746494284698] Val Score : [0.9097393418694286])\n",
      "Epoch : [372] Train loss : [0.022182513028383255] Val Score : [0.9097393418694286])\n",
      "Epoch : [373] Train loss : [0.023549784773162434] Val Score : [0.9097393418694286])\n",
      "Epoch : [374] Train loss : [0.020538901378001486] Val Score : [0.9097393418694286])\n",
      "Epoch : [375] Train loss : [0.023208844076309885] Val Score : [0.9097393418694286])\n",
      "Epoch : [376] Train loss : [0.02151473318891866] Val Score : [0.9097393418694286])\n",
      "Epoch : [377] Train loss : [0.021039302593895366] Val Score : [0.9097393418694286])\n",
      "Epoch : [378] Train loss : [0.019780855625867844] Val Score : [0.9097393418694286])\n",
      "Epoch : [379] Train loss : [0.023545555770397186] Val Score : [0.9097393418694286])\n",
      "Epoch : [380] Train loss : [0.020520272265587534] Val Score : [0.9097393418694286])\n",
      "Epoch : [381] Train loss : [0.021079680749348233] Val Score : [0.9097393418694286])\n",
      "Epoch : [382] Train loss : [0.021582367164748057] Val Score : [0.9097393418694286])\n",
      "Epoch : [383] Train loss : [0.020033021324447224] Val Score : [0.9097393418694286])\n",
      "Epoch : [384] Train loss : [0.022734820576650754] Val Score : [0.9097393418694286])\n",
      "Epoch : [385] Train loss : [0.02097823018474238] Val Score : [0.9097393418694286])\n",
      "Epoch : [386] Train loss : [0.021285174414515495] Val Score : [0.9097393418694286])\n",
      "Epoch : [387] Train loss : [0.024882196049605097] Val Score : [0.9097393418694286])\n",
      "Epoch : [388] Train loss : [0.021185608048524176] Val Score : [0.9097393418694286])\n",
      "Epoch : [389] Train loss : [0.022933684023363248] Val Score : [0.9097393418694286])\n",
      "Epoch : [390] Train loss : [0.020789010982428278] Val Score : [0.9097393418694286])\n",
      "Epoch : [391] Train loss : [0.02314286625811032] Val Score : [0.9097393418694286])\n",
      "Epoch : [392] Train loss : [0.021906516647764614] Val Score : [0.9097393418694286])\n",
      "Epoch : [393] Train loss : [0.019845235028437207] Val Score : [0.9097393418694286])\n",
      "Epoch : [394] Train loss : [0.022824880001800402] Val Score : [0.9097393418694286])\n",
      "Epoch : [395] Train loss : [0.021159626277429715] Val Score : [0.9097393418694286])\n",
      "Epoch : [396] Train loss : [0.02068835629948548] Val Score : [0.9097393418694286])\n",
      "Epoch : [397] Train loss : [0.02030814758368901] Val Score : [0.9097393418694286])\n",
      "Epoch : [398] Train loss : [0.021385871140020236] Val Score : [0.9097393418694286])\n",
      "Epoch : [399] Train loss : [0.020308445074728558] Val Score : [0.9097393418694286])\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder())\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.checkpoint/best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m AutoEncoder()\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m.checkpoint/best_model.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDataParallel(model)\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/yb22/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/yb22/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/yb22/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.checkpoint/best_model.pth'"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load('./checkpoint/best_model.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yb22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec8e4c77fe3646f154ba479e6fc70a8bb19764cdb348f9e18cb8a0833f3a63d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
